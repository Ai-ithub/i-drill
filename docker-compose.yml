version: "3.9"

# ===== SECURITY WARNING =====
# This file uses environment variables from .env file.
# NEVER commit .env files to version control!
# 
# Setup:
#   1. Copy docker-compose.env.example to .env
#   2. Edit .env with secure passwords
#   3. Run: docker-compose up
#
# Required environment variables:
#   - POSTGRES_PASSWORD (minimum 16 characters)
#   - SECRET_KEY (minimum 32 characters)
#   - DEFAULT_ADMIN_PASSWORD (minimum 12 characters)

services:
  fastapi:
    build: .
    container_name: i-drill-fastapi
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_started
      zookeeper:
        condition: service_started
      redis:
        condition: service_healthy
      mlflow:
        condition: service_started
    ports:
      - "8001:8001"
    working_dir: /src/backend
    command: uvicorn app:app --host 0.0.0.0 --port 8001
    env_file:
      - .env
    environment:
      - PYTHONPATH=/src/backend
      - APP_ENV=${APP_ENV:-development}
      # SECRET_KEY must be set in .env file (no default for security)
      - SECRET_KEY=${SECRET_KEY}
      - ALLOWED_ORIGINS=${ALLOWED_ORIGINS:-http://localhost:5173,http://localhost:5175}
      - RATE_LIMIT_DEFAULT=200/minute
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - REDIS_PASSWORD=${REDIS_PASSWORD:-}
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - MLFLOW_EXPERIMENT_NAME=i-drill-models
      # Database connection (uses POSTGRES_USER and POSTGRES_PASSWORD from .env)
      - DATABASE_URL=postgresql://${POSTGRES_USER:-drill_user}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-drilling_db}
      # Default admin account (must be set in .env)
      - DEFAULT_ADMIN_USERNAME=${DEFAULT_ADMIN_USERNAME:-admin}
      - DEFAULT_ADMIN_PASSWORD=${DEFAULT_ADMIN_PASSWORD}
      - DEFAULT_ADMIN_EMAIL=${DEFAULT_ADMIN_EMAIL:-admin@example.com}
    volumes:
      - ./src:/src
      - mlflow_artifacts:/mlflow/artifacts

  zookeeper:
    image: confluentinc/cp-zookeeper:7.7.0
    container_name: i-drill-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.7.0
    container_name: i-drill-kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181

      # Two listeners: one for containers (kafka:9092), one for host tools (localhost:29092)
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT

      # Single-broker dev sanity
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1

      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 5s
      retries: 10

  postgres:
    image: postgres:16-alpine
    container_name: i-drill-postgres
    env_file:
      - .env
    environment:
      # Use environment variables from .env file (no hardcoded passwords)
      POSTGRES_DB: ${POSTGRES_DB:-drilling_db}
      POSTGRES_USER: ${POSTGRES_USER:-drill_user}
      # POSTGRES_PASSWORD must be set in .env file (no default for security)
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-drill_user}"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7.4-alpine
    container_name: i-drill-redis
    env_file:
      - .env
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    # Use password if provided in .env (recommended for production)
    command: >
      sh -c "
      if [ -n \"$$REDIS_PASSWORD\" ]; then
        redis-server --appendonly yes --requirepass \"$$REDIS_PASSWORD\"
      else
        redis-server --appendonly yes
      fi
      "
    healthcheck:
      test: >
        sh -c "
        if [ -n \"$$REDIS_PASSWORD\" ]; then
          redis-cli -a \"$$REDIS_PASSWORD\" ping
        else
          redis-cli ping
        fi
        "
      interval: 10s
      timeout: 5s
      retries: 5

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.15.0
    container_name: i-drill-mlflow
    ports:
      - "5000:5000"
    env_file:
      - .env
    environment:
      - MLFLOW_BACKEND_STORE_URI=postgresql://${POSTGRES_USER:-drill_user}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-drilling_db}
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=/mlflow/artifacts
    volumes:
      - mlflow_artifacts:/mlflow/artifacts
    command: >
      mlflow server
      --backend-store-uri postgresql://${POSTGRES_USER:-drill_user}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-drilling_db}
      --default-artifact-root /mlflow/artifacts
      --host 0.0.0.0
      --port 5000
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:5000/health').read()"]
      interval: 10s
      timeout: 5s
      retries: 5

  producer:
    build: .
    container_name: i-drill-producer
    working_dir: /src/backend
    command: python Producer.py
    environment:
      - PYTHONPATH=/src/backend
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    volumes:
      - ./src:/src
    depends_on:
      kafka:
        condition: service_started
      zookeeper:
        condition: service_started
    restart: on-failure

  consumer:
    build: .
    container_name: i-drill-consumer
    working_dir: /src/backend
    command: python Consumer.py
    environment:
      - PYTHONPATH=/src/backend
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    volumes:
      - ./src:/src
    depends_on:
      kafka:
        condition: service_started
      zookeeper:
        condition: service_started
    restart: on-failure

volumes:
  postgres_data:
    driver: local
  influxdb_data:
    driver: local
  redis_data:
    driver: local
  mlflow_artifacts:
    driver: local